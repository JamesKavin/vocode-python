---
title: "Synthesizer"
description: "Used to bring text-to-speech from a variety of providers."
---

## Overview

To produce sound in the conversation, developers can specify a synthesizer configuration
that matches their needs.

## SynthesizerConfig Class

The base `SynthesizerConfig` class defines several key fields that all implementations
use.

<ParamField path="sampling_rate" type="int" required={true}>
  The sampling rate of the audio to be synthesized.
</ParamField>

<ParamField path="audio_encoding" type="AudioEncoding" required={true}>
  The encoding format of the audio to be synthesized.
</ParamField>

## Synthesizer Implementations

### AzureSynthesizerConfig

Experiment with Azure voices on their [web playground](https://azure.microsoft.com/en-us/products/cognitive-services/text-to-speech/#features)

<ParamField path="voice_name" type="Optional[str]" required={false}>
  The voice name to be used for synthesis.
</ParamField>

<ParamField path="pitch" type="Optional[int]" required={false}>
  The pitch shift to apply to the synthesized audio. Ranges from [-50, 50].
</ParamField>

<ParamField path="rate" type="Optional[int]" required={false}>
  The speaking rate to use for synthesis, specified as a percentage of the
  default rate (rate=20 means 120% faster than the default)
</ParamField>

### ElevenLabsSynthesizerConfig

[ElevenLabs](https://beta.elevenlabs.io/) is the state-of-the-art TTS/voice cloning
API. Note that their API latency is unreliable and traffic based (it can
spike from sub-second latency to >5 seconds). Also, it is not compatible with our
bash demo (only works on web).

<ParamField path="api_key" type="str" required={true}>
  Your API key to use for authentication with the ElevenLabs API.
</ParamField>

<ParamField path="voice_id" type="Optional[str]" required={false}>
  The ID of the voice to use for synthesis.
</ParamField>
